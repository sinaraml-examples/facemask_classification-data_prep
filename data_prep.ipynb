{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a281c4-d0fd-40c4-9849-91d0f1669678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bebf8f4-cdbe-4ace-9fa5-e0300e2a1fc5",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# specify substep parameters for interactive run\n",
    "# this cell will be replaced during job run with the parameters from json within params subfolder\n",
    "substep_params={\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b0f470-dc4b-4605-b329-410a3b368ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pipeline and step parameters - do not edit\n",
    "from sinara.substep import get_pipeline_params, get_step_params\n",
    "pipeline_params = get_pipeline_params(pprint=True)\n",
    "step_params = get_step_params(pprint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6426737-251e-46c2-9fc4-66efd6389921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define substep interface\n",
    "from sinara.substep import NotebookSubstep, ENV_NAME, PIPELINE_NAME, ZONE_NAME, STEP_NAME, RUN_ID, ENTITY_NAME, ENTITY_PATH, SUBSTEP_NAME\n",
    "\n",
    "substep = NotebookSubstep(pipeline_params, step_params, substep_params)\n",
    "\n",
    "substep.interface(\n",
    "    inputs =\n",
    "    [\n",
    "        {STEP_NAME: \"data_load\", ENTITY_NAME: \"facemask_datasets\"}, # images from data_load step\n",
    "    ],\n",
    "    tmp_entities =\n",
    "    [    \n",
    "        { ENTITY_NAME: \"facemask_datasets\"}, # extracted temporary images from Sinara Archive\n",
    "        { ENTITY_NAME: \"facemask_train_dataset\"}, # temporary facemask dataset for classificator train\n",
    "        { ENTITY_NAME: \"facemask_val_dataset\"}, # temporary facemask dataset for classificator eval\n",
    "        { ENTITY_NAME: \"facemask_test_dataset\"}, # temporary facemask dataset for classificator test\n",
    "    ],\n",
    "    outputs = \n",
    "    [\n",
    "        { ENTITY_NAME: \"train_dataset\"}, # dataset archived for classificator train\n",
    "        { ENTITY_NAME: \"val_dataset\"}, # dataset archived  for classificator eval\n",
    "        { ENTITY_NAME: \"test_dataset\"}, # dataset archived  for classificator test\n",
    "    ]\n",
    ")\n",
    "\n",
    "substep.print_interface_info()\n",
    "\n",
    "substep.exit_in_visualize_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83adbbd-6f01-403f-b68b-2cc70343fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify all notebook wide libraries imports here\n",
    "# Sinara lib imports is left in the place of their usage\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import json\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from utils.utils import convert_facemask_detectons_to_coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76aa12-771f-4a41-a999-599396e10cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run spark\n",
    "from sinara.spark import SinaraSpark\n",
    "from sinara.archive import SinaraArchive\n",
    "\n",
    "spark = SinaraSpark.run_session(0)\n",
    "archive = SinaraArchive(spark)\n",
    "SinaraSpark.ui_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a28711-f22f-40c9-b0fc-02187c04b559",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading cifar10_datasets_images (from the previous step data_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16757091-17a6-4ba3-b922-d0a5528ae21f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = substep.inputs(step_name = \"data_load\")\n",
    "tmp_entities = substep.tmp_entities()\n",
    "\n",
    "# copy data from previos step to tmp_entities\n",
    "archive.unpack_files_from_store_to_tmp(store_path=inputs.facemask_datasets, tmp_entity_dir=tmp_entities.facemask_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1363411-7090-4ca8-b173-0aa24079ba78",
   "metadata": {},
   "source": [
    "### Convert facemask annotations to image classification annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffc897c-cdd1-413d-90fa-e14a68dce9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_annotations = osp.join(tmp_entities.facemask_datasets, \"ds\", \"ann\")\n",
    "coco_annotations = convert_facemask_detectons_to_coco(dir_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c4de9d-31c8-49f1-8a0f-e591ecad9480",
   "metadata": {},
   "source": [
    "#### Cropping images by object facemask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402f4c29-d1f7-48d4-8a3e-74c189f10ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_images = osp.join(tmp_entities.facemask_datasets, \"ds\", \"img\")\n",
    "dir_crop_images = osp.join(tmp_entities.facemask_datasets, \"crop\")\n",
    "os.makedirs(dir_crop_images, exist_ok=True)\n",
    "\n",
    "categories = {cat_info[\"id\"]: cat_info[\"name\"] for cat_info in coco_annotations[\"categories\"]}\n",
    "df_annotations = pd.DataFrame(coco_annotations[\"annotations\"])\n",
    "\n",
    "for image_info in tqdm(coco_annotations[\"images\"]):\n",
    "    image_name = image_info[\"file_name\"]\n",
    "    image_path = osp.join(dir_images, image_name)\n",
    "    image_id = image_info[\"id\"]\n",
    "    image_annotations = df_annotations[df_annotations[\"image_id\"] == image_id]\n",
    "    image = cv2.imread(image_path)\n",
    "    for id_row, row in image_annotations.iterrows():\n",
    "        x_tl, y_tl, w_obj, h_obj = row[\"bbox\"]\n",
    "        category_id = row[\"category_id\"]\n",
    "        obj_id = row[\"id\"]\n",
    "        \n",
    "        x_br = x_tl + w_obj\n",
    "        y_br = y_tl + h_obj\n",
    "        image_crop = image[y_tl:y_br, x_tl:x_br]        \n",
    "        category_name = categories[category_id]\n",
    "        image_crop_path = osp.join(dir_crop_images, category_name, f\"{str(obj_id)}_{image_name}\")\n",
    "        os.makedirs(osp.dirname(image_crop_path), exist_ok=True)\n",
    "        cv2.imwrite(image_crop_path, image_crop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3ccc6b-8f20-457f-97fc-79b742be49eb",
   "metadata": {},
   "source": [
    "## Get image pathes for facemask dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca11695d-f808-4eb4-bf40-98f6dfdd187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = os.listdir(dir_crop_images)\n",
    "facemask_dataset = []\n",
    "for class_name in class_names:\n",
    "    # Get images from dataset\n",
    "    for img_name in os.listdir(osp.join(dir_crop_images, class_name)):        \n",
    "        img_path = osp.join(dir_crop_images, class_name, img_name)\n",
    "        if osp.isdir(img_path):\n",
    "            continue\n",
    "        facemask_dataset.append(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2c1b1c-0164-40db-a583-eb624bf54052",
   "metadata": {},
   "source": [
    "### Split Cifar10 Dataset to Train, Valid and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a889268-8363-43f5-afda-eaa4c6786e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to train, valid and test parts\n",
    "train_facemask_images, val_facemask_images = train_test_split(facemask_dataset, test_size=0.33, random_state=42)\n",
    "val_facemask_images, test_facemask_images = train_test_split(val_facemask_images, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6da8ec3-5a2b-41c4-8d99-cfe2934d32d1",
   "metadata": {},
   "source": [
    "## Review FaceMask Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88d8eeb-a5a0-47aa-80be-65330ca2e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's view more images in a grid format\n",
    "# Define the dimensions of the plot grid \n",
    "W_grid = 5\n",
    "H_grid = 5\n",
    "\n",
    "# fig, axes = plt.subplots(L_grid, W_grid)\n",
    "# subplot return the figure object and axes object\n",
    "# we can use the axes object to plot specific figures at various locations\n",
    "fig, axes = plt.subplots(H_grid, W_grid, figsize = (10,10))\n",
    "\n",
    "axes = axes.ravel() # flaten the 15 x 15 matrix into 225 array\n",
    "\n",
    "n_train = len(train_facemask_images) # get the length of the train dataset\n",
    "\n",
    "# Select a random number from 0 to n_train\n",
    "for i in range(W_grid * H_grid): # create evenly spaces variables \n",
    "    # Select a random number\n",
    "    image_index = np.random.randint(0, n_train)\n",
    "    # read and display an image with the selected index\n",
    "    img_path = train_facemask_images[image_index]\n",
    "    label_name = osp.basename(osp.dirname(img_path))\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(label_name, fontsize = 8)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa885d-02d7-4930-97d1-ae22091b37c6",
   "metadata": {},
   "source": [
    "### Overview of the distribution of labeled data from train, valid and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef0a759-10b4-4602-833c-72b0fe0de3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_barh_labels(cifar10_images: list, title_name: str = \"\", num_fig = 0):\n",
    "    facemask_labels = [osp.basename(osp.dirname(fpath)) for fpath in cifar10_images]\n",
    "    labels, counts = np.unique(facemask_labels, return_counts=True)\n",
    "    fig = plt.figure()\n",
    "    plt.barh(labels, counts)\n",
    "    plt.title(title_name)\n",
    "    plt.show()\n",
    "\n",
    "# distribution of labeled data from train dataset\n",
    "plot_barh_labels(train_facemask_images, 'Class distribution in training dataset', 0)\n",
    "\n",
    "# distribution of labeled data from valid dataset\n",
    "plot_barh_labels(val_facemask_images, 'Class distribution in validation dataset', 1)\n",
    "\n",
    "# # distribution of labeled data from test dataset\n",
    "plot_barh_labels(test_facemask_images, 'Class distribution in testing dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a13221d-3524-497e-9761-fac7b0b4419f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save temporarily train, validation and test cifar10 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b203dbcc-0356-476c-8e0e-28d37feb1dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save images for train, validation and test cifar10 datasets to tmp_entities\n",
    "def prepare_facemask_dataset_images(facemask_images, dest_img_folder: str):\n",
    "    pack = []\n",
    "    for source_img_path in tqdm(facemask_images):\n",
    "        label_img = osp.basename(osp.dirname(source_img_path))\n",
    "        dest_img_path = osp.join(dest_img_folder, label_img, osp.basename(source_img_path))\n",
    "        os.makedirs(osp.dirname(dest_img_path), exist_ok=True)\n",
    "        shutil.copyfile(source_img_path, dest_img_path)\n",
    "\n",
    "prepare_facemask_dataset_images(train_facemask_images, dest_img_folder=tmp_entities.facemask_train_dataset )\n",
    "prepare_facemask_dataset_images(val_facemask_images, dest_img_folder=tmp_entities.facemask_val_dataset)\n",
    "prepare_facemask_dataset_images(test_facemask_images, dest_img_folder=tmp_entities.facemask_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90687e97-db34-493a-b087-184f62fc2a34",
   "metadata": {},
   "source": [
    "### Archiving train, validation and test cifar10 datasets to Sinara Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305aec9c-b4ae-4f15-bba2-65577c70d189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save tmp_entities (facemask_train_dataset, facemask_val_dataset, facemask_test_dataset) to outputs of step data_prep\n",
    "outputs = substep.outputs()\n",
    "\n",
    "archive.pack_files_from_tmp_to_store(tmp_entity_dir=tmp_entities.facemask_train_dataset, store_path=outputs.train_dataset)\n",
    "archive.pack_files_from_tmp_to_store(tmp_entity_dir=tmp_entities.facemask_val_dataset, store_path=outputs.val_dataset)\n",
    "archive.pack_files_from_tmp_to_store(tmp_entity_dir=tmp_entities.facemask_test_dataset, store_path=outputs.test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44dab20-5483-485e-b734-3042135d48d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stop spark\n",
    "SinaraSpark.stop_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b630e1b5-a12b-4c58-80a0-0b781871b65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d0217-9b9c-4ce8-8c51-ad0ff48b9780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
